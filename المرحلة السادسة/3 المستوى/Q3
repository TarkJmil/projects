مكتبة SpeechRecognition في Python تُستخدم لمعالجة وتحليل الصوت وتحويله إلى نص. يمكنك دمج تقنيات الذكاء الاصطناعي في تطبيقات التعرف على الصوت عبر تحسين جودة المدخلات الصوتية، وتدريب نماذج مخصصة، أو استخدام نماذج التعرف التلقائي على الكلام (ASR) المدعومة بالذكاء الاصطناعي.

1. إعداد مكتبة SpeechRecognition

أولًا، قم بتثبيت المكتبة عبر:

pip install SpeechRecognition

2. استخدام SpeechRecognition مع محركات التعرف على الصوت

تدعم المكتبة عدة محركات مثل Google Web Speech API، Sphinx، IBM Watson، وغيرهم.

استخدام Google Web Speech API

import speech_recognition as sr

recognizer = sr.Recognizer()

with sr.Microphone() as source:
    print("تحدث الآن...")
    recognizer.adjust_for_ambient_noise(source)
    audio = recognizer.listen(source)

try:
    text = recognizer.recognize_google(audio, language="ar-SA")
    print("النص المحول:", text)
except sr.UnknownValueError:
    print("لم يتم التعرف على الصوت")
except sr.RequestError:
    print("حدثت مشكلة في الاتصال بخادم التعرف على الصوت")

3. تحسين جودة الصوت باستخدام مكتبة OpenCV أو librosa

لتصفية الضوضاء، يمكن استخدام librosa أو wave لمعالجة الصوت قبل تمريره إلى النموذج:

pip install librosa numpy

import librosa
import numpy as np

def preprocess_audio(file_path):
    y, sr = librosa.load(file_path, sr=16000)
    y = librosa.effects.preemphasis(y)
    return y, sr

4. استخدام نماذج الذكاء الاصطناعي المخصصة

إذا كنت تريد نتائج أكثر دقة، يمكنك استخدام نماذج تعلم عميق مثل Wav2Vec2 من Facebook AI أو DeepSpeech من Mozilla.

استخدام Wav2Vec2 من Hugging Face

pip install transformers torch torchaudio

from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
import torch
import librosa

model_name = "facebook/wav2vec2-large-xlsr-53-ar"
processor = Wav2Vec2Processor.from_pretrained(model_name)
model = Wav2Vec2ForCTC.from_pretrained(model_name)

def transcribe_audio(file_path):
    audio, rate = librosa.load(file_path, sr=16000)
    input_values = processor(audio, return_tensors="pt", sampling_rate=16000).input_values
    with torch.no_grad():
        logits = model(input_values).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.batch_decode(predicted_ids)[0]
    return transcription

print(transcribe_audio("audio_file.wav"))

5. تحسين النطق والتفاعل باستخدام NLP

لتحليل النص المستخرج وتحسين التفاعل، يمكن دمجه مع spaCy أو Transformers:

pip install spacy

import spacy
nlp = spacy.load("ar_core_news_sm")

text = "أريد البحث عن الطقس في الرياض"
doc = nlp(text)

for ent in doc.ents:
    print(ent.text, ent.label_)

ملخص

SpeechRecognition: للتعرف على الصوت باستخدام محركات مثل Google.

librosa و wave: لتحسين جودة الصوت وإزالة الضوضاء.

Wav2Vec2 أو DeepSpeech: لاستخدام نماذج الذكاء الاصطناعي في التعرف على الصوت بدقة أكبر.

spaCy أو Transformers: لتحليل وفهم النصوص المستخرجة.